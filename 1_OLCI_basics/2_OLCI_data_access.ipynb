{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/EU-Copernicus-EUM_3Logos.png' alt='Logo EU Copernicus EUMETSAT' align='right' width='50%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"11_OLCI_overview.iynb\"><< OLCI Overview</a><span style=\"float:right;\"><a href=\"./13_OLCI_spatial_interrogation.ipynb\">1.2 - OLCI spatial interrogation >></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OLCI Data Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook describes a number of ways that you can access OLCI data from the Sentinel-3 missions, as provided by EUMETSAT.\n",
    "\n",
    "The notebook works through the following steps. You don't have to run all of these, you can decide which method you want to use to access the data.If you want to run the following notebooks as is (i.e. without customisation - recommended for new users), choose from steps 2, 3 (or 4.3 for advanced users!). Other options are provided for information and will require you to customise the following notebooks to account for different data. \n",
    "\n",
    " - [1. Create a folder to store your data](#data_folder)\n",
    " - [2. Manually search for datasets on CODA](#coda_search)\n",
    " - [3. Search for datasets on WEkEO](#wekeo_search)\n",
    " - [4. Further options for getting data](#other_data)\n",
    "     - [4.1. Reprocessed data on CODA REP](#codarep_search)\n",
    "     - [4.2. Older data from the EUMETSAT data centre](#datacentre_search)\n",
    "     - [4.3. Downloading data from CODA using the API](#sentinel_downloader)\n",
    "     - [4.4. OLCI maps and data from EUMETView WMS and WCS](#olci_eumetview)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='data_folder'></a>1. Create a folder to store your data\n",
    "\n",
    "In this section we will create a folder to store the data we download. \n",
    "\n",
    "First we will import any Python packages and functions that we want to use. For this section, we will import some packages that allow us to create folders that our notebook can find. In latter sections we will import some other functions to help us download data. Normally it's best practice to import all your packages and functions at the top of your script, as you'll see in the following notebooks. For now we'll import as we go, so you can understand the purpose of the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # This package allows us to use Python to interact with the operating system of the\n",
    "          # system - computer/hosted processing environment - we are working on.\n",
    "import sys # This is another Python package supporting system related operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running code, it is very useful to understand the concept of a 'path'. Paths tell us (and our code!) where to find things. This could include data, a script/piece of code, or pieces of software etc.\n",
    "\n",
    "We can find the path to this notebook as shown below, by asking Python to print the output when we use the 'os' package we have just imported, and a function it provides called 'getcwd' where cwd stands for current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evers\\Desktop\\git_reps\\Ocean\\learn_olci\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will create a folder in this same directory, to store the OLCI data we want to work with in the following notebooks. We can do this using another function from the 'os' package - called 'mkdir' which makes folders.\n",
    "\n",
    "We will then use another function from os called '.path.join' that will take the path for the current working directory, and join a new part - the name of our . This process also creates the new folder in the path, if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(),'olci_data')):\n",
    "    os.mkdir('olci_data')\n",
    "    \n",
    "download_dir_path = os.path.join(os.getcwd(),'olci_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look in the folder where you have this notebook saved, you should see a folder called 'olci_data'. Alternatively, you can use another command from the 'os' package (listdir), to show the files in the folder (also known as a directory) that you are running this notebook in now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.gitmodules',\n",
       " '.ipynb_checkpoints',\n",
       " '1_OLCI_overview.ipynb',\n",
       " '2_OLCI_data_access.ipynb',\n",
       " '3_OLCI_spatial_interrogation.ipynb',\n",
       " '4_OLCI_spectral_interrogation.ipynb',\n",
       " '5_OLCI_CHL_comparison.ipynb',\n",
       " '6_OLCI_spectral_AC_L1_L2_comparison.ipynb',\n",
       " '7_OLCI_water_constituents.ipynb',\n",
       " 'AUTHORS.txt',\n",
       " 'img',\n",
       " 'json_templates',\n",
       " 'learn-olci.ABOUT',\n",
       " 'LICENSE.txt',\n",
       " 'olci_data',\n",
       " 'README.md',\n",
       " 'wekeo_hda']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='data_folder'></a>2. Manually search for data sets on CODA\n",
    "\n",
    "In this section we will describe the first of several options for downloading some OLCI data to use in the following notebooks. \n",
    "\n",
    "EUMETSAT provides a browser interface for interactively searching for data from the Sentinel-3 satellites - the Copernicus Online Data Access (CODA). You can find CODA at this [link](https://coda.eumetsat.int). This is a useful approach to take if you want to have a quick look at the data before your download it, or if you aren't yet comfortable with using more programming based approaches to data access.\n",
    "\n",
    "To download data, you will need an eoportal account. When you go to the CODA webpage, you will be prompted to sign in with your account details, or sign up (if you don't yet have an account).\n",
    "\n",
    "You can use the various functionalities of CODA to search for data from a specific time and region, by satellite (Sentinel-3A or B), resolution (FR - full resolution of 300m, or RR, reduced resolution of 1km), timeliness of the product (NR - Near Real Time, available within 3 hours of sensing or NT - Non-time critical, available within 30 days, and including improved metadata for processing). The video linked below shows how CODA can be used for OLCI data.\n",
    "\n",
    "[![CODA OLCI VIDEO](http://img.youtube.com/vi/V3NAuafvlFM/0.jpg)](http://www.youtube.com/watch?v=V3NAuafvlFM \"Click to watch a video tutorial on using CODA\")\n",
    "\n",
    "For the rest of the notebooks in this module, we recommend downloading the following file S3B_OL_2_WRR____20210129T105252_20210129T113639_20210129T131850_2627_048_265______MAR_O_NR_002.\n",
    "\n",
    "You can search for this file, by drawing a small box over the English channel or coast of North-West Africa, selecting a sensing period including 2021-01-29, and then the correct product type, which in this case is \"OL_2_WRR\". Alternatively, the following link will download the file directly: https://coda.eumetsat.int/odata/v1/Products('18ac21df-514e-46e1-9caa-8d99697fd0f0')/$value \n",
    "\n",
    "If this is your chosen option, you need to download this file and place it in the olci_data folder we created before, and make sure it is unzipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='wekeo_search'></a>3. Search for datasets on WEkEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WEkEO](https://www.wekeo.eu/) is the European Commission Copernicus DIAS (Data and Information Access Service) reference service for environmental data, virtual processing environments and skilled user support. WEkEO offers access to a variety of data, including different parameters from Sentinel-1, Sentinel-2 and Sentinel-3. It further offers access to climate reanalysis and seasonal forecast data. The [Harmonised Data Access (HDA) API](https://www.wekeo.eu/documentation/using_jupyter_notebooks), a REST interface, allows users to subset and download datasets from WEkEO. This is a good option to choose if you are already working in the WEkEO system (i.e. on JupyterLab or a virtual machine as you will benefit from fast access to the data) or if you are wanting to learn about accessing data using programming approaches (these can then be readily scaled up for routine or batch data access). \n",
    "\n",
    "You can use this section to get data to work with in the following notebooks, if you have a WEkEO account (this is different from your CODA account). If you are already using this notebook in WEkEO (e.g. on the JupyterLab) you will have this already, but if not, you can register for an account at www.wekeo.eu.\n",
    "\n",
    "You can work through a detailed example using the HDA in the wekeo-hda module, either available through the code you have been given access to during this training course, or from the WEkEO github (GITHUB LINK). This notebook makes use of functions stored in the Python script [hda_api_functions](./hda_api_functions.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import WEkEO HDA functions\n",
    "from wekeo_hda import hda_api_functions as hapi # These are some custom functions we have provided to help access the HDA\n",
    "from IPython.core.display import HTML # A function to display from HTML\n",
    "import json # A package to work with json files\n",
    "from zipfile import ZipFile # A function to work with zipped files \n",
    "import glob # A function that can help find things (files etc)\n",
    "import warnings # This package helps communicate about problems encountered when code is run\n",
    "warnings.filterwarnings('ignore') # This surpresses warnings. We use this to reduce what you see printed to screen in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to use the HDA-API we need to provide some authentication credentials, which comes in the form of an API key and API token. In this notebook we have provided functions so you can retrieve the API key and token you need directly using your username and password for WEkEO. You can find out more about this process in the notebook on HDA access (wekeo_harmonized_data_access_api.ipynb) that can be found in the **wekeo-hda** folder on your Jupyterlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Your API key is: <b>aGVrMTc6Q2FkYnVyeTE3IQ==</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your WEkEO API username and password (needs to be in '  ')\n",
    "user_name = 'USERNAME'\n",
    "password = 'PASSWORD'\n",
    "\n",
    "# Generate an API key\n",
    "api_key = hapi.generate_api_key(user_name, password)\n",
    "display(HTML('Your API key is: <b>'+api_key+'</b>'))\n",
    "\n",
    "# set this key to true to download data, if you have already downloaded the data, you can set it to false\n",
    "download_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# where we can find our data query form:\n",
    "JSON_query_dir = os.path.join(os.getcwd(),'json_templates')\n",
    "# HDA-API loud and noisy?\n",
    "verbose = False\n",
    "\n",
    "# make the output directory if required\n",
    "if not os.path.exists(download_dir_path):\n",
    "    os.makedirs(download_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set how we want the script to run, we are ready to get some data. We start this process by telling the script what kind of data we want. In this case, this is OLCI L2 reduced resolution data, which has the following designation on WEkEO: **EO:EUM:DAT:SENTINEL-3:OL_2_WRR___**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLCI REDUCED RESOLUTION LEVEL 2 DATASET ID\n",
    "dataset_id = \"EO:EUM:DAT:SENTINEL-3:OL_2_WRR___\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use this dataset_id to find the correct, locally stored JSON query file which describes the data we want. The query file is called: **json_templates/EO_EUM_DAT_SENTINEL-3_OL_2_WRR___.json**\n",
    "\n",
    "These 'JSON' queries are what we use to ask WEkEO for data. They have a very specific form, but allow us quite fine grained control over what data to get. This JSON file is customised already to find the file we have recommended above, but you can also use it as a template for your own needs when you want to download other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found JSON query file for EO:EUM:DAT:SENTINEL-3:OL_2_WRR___\n"
     ]
    }
   ],
   "source": [
    "# find query file\n",
    "JSON_query_file = os.path.join(JSON_query_dir,dataset_id.replace(':','_')+\".json\")\n",
    "if not os.path.exists(JSON_query_file):\n",
    "    print('Query file ' + JSON_query_file + ' does not exist')\n",
    "else:\n",
    "    print('Found JSON query file for '+dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a query, we need to launch it to WEkEO to get our data. The box below takes care of this through the following steps:\n",
    "    1. initialise our HDA-API\n",
    "    2. get an access token for our data\n",
    "    3. accepts the WEkEO terms and conditions\n",
    "    4. loads our JSON query into memory\n",
    "    5. launches our search\n",
    "    6. waits for our search results\n",
    "    7. gets our result list\n",
    "    8. downloads our data\n",
    "\n",
    "This is quite a complex process, so much of the functionality has been buried 'behind the scenes'. If you want more information, you can check out the **wekeo-hda** tool kit in the parent training directory. The code below will report some information as it runs. At the end, it should tell you that one product has been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting an access token. This token is valid for one hour only.\n",
      "Success: Access token is 00bc8bdc-2dbd-3a9f-ba99-08f11c8bc6b6\n",
      "Copernicus_General_License Terms and Conditions already accepted\n",
      "Launching job...\n",
      "Query successfully submitted. Job ID is 9wB1a3rmF4wQfOoQVPVo2a_DnqU\n",
      "Next check in 5 seconds\n",
      "Query successfully submitted. Status is running\n",
      "Next check in 10 seconds\n",
      "Query successfully submitted. Status is running\n",
      "Next check in 15 seconds\n",
      "Query successfully submitted. Status is completed\n",
      "Getting results...\n",
      "************** Results *******************************\n",
      "{\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"downloadUri\": null,\n",
      "            \"filename\": \"S3B_OL_2_WRR____20210129T105252_20210129T113639_20210129T131850_2627_048_265______MAR_O_NR_002\",\n",
      "            \"order\": null,\n",
      "            \"productInfo\": {\n",
      "                \"datasetId\": \"EO:EUM:DAT:SENTINEL-3:OL_2_WRR___\",\n",
      "                \"product\": \"S3B_OL_2_WRR____20210129T105252_20210129T113639_20210129T131850_2627_048_265______MAR_O_NR_002\",\n",
      "                \"productEndDate\": \"2021-01-29T11:36:39.324000Z\",\n",
      "                \"productStartDate\": \"2021-01-29T10:52:51.861000Z\"\n",
      "            },\n",
      "            \"size\": 411261992,\n",
      "            \"url\": \"18ac21df-514e-46e1-9caa-8d99697fd0f0/S3B_OL_2_WRR____20210129T105252_20210129T113639_20210129T131850_2627_048_265______MAR_O_NR_002\"\n",
      "        }\n",
      "    ],\n",
      "    \"itemsInPage\": 1,\n",
      "    \"nextPage\": null,\n",
      "    \"page\": 0,\n",
      "    \"pages\": 1,\n",
      "    \"previousPage\": null,\n",
      "    \"totItems\": 1\n",
      "}\n",
      "*******************************************\n",
      "Query successfully submitted. Order ID is T1sKdI2UK8V_GaXdqQLeYDzZVjM\n",
      "Next check in 5 seconds\n",
      "Query successfully submitted. Status is completed\n",
      "Downloading data...\n",
      "Downloading C:\\Users\\Evers\\Desktop\\git_reps\\Ocean\\learn_olci\\olci_data\\S3B_OL_2_WRR____20210129T105252_20210129T113639_20210129T131850_2627_048_265______MAR_O_NR_002.zip\n",
      "File size is:   392.21 MB\n",
      "[==================================================]     14.63 Mbps[  392.22] MB downloaded, 14961.92 kbps\n",
      "Download complete...\n",
      "Time Elapsed: 26.84375 seconds\n"
     ]
    }
   ],
   "source": [
    "if download_data:\n",
    "    HAPI_dict = hapi.init(dataset_id, api_key, download_dir_path)\n",
    "    HAPI_dict = hapi.get_access_token(HAPI_dict)\n",
    "    HAPI_dict = hapi.acceptTandC(HAPI_dict)\n",
    "\n",
    "    # load the query\n",
    "    with open(JSON_query_file, 'r') as f:\n",
    "        query = json.load(f)\n",
    "\n",
    "    # launch job\n",
    "    print('Launching job...')\n",
    "    HAPI_dict = hapi.get_job_id(HAPI_dict, query)\n",
    "\n",
    "    # check results\n",
    "    print('Getting results...')\n",
    "    HAPI_dict = hapi.get_results_list(HAPI_dict)\n",
    "    HAPI_dict = hapi.get_order_ids(HAPI_dict)\n",
    "\n",
    "    # download data\n",
    "    print('Downloading data...')\n",
    "    HAPI_dict = hapi.download_data(HAPI_dict, file_extension='.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel data is usually distributed as a zip file, which contains the SAFE format data within. To use this, we must unzip the file. The box below handles this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping file\n"
     ]
    }
   ],
   "source": [
    "if download_data:\n",
    "    # unzip file\n",
    "    for filename in HAPI_dict['filenames']:\n",
    "        if os.path.splitext(filename)[-1] == '.zip':\n",
    "            print('Unzipping file')\n",
    "            try:\n",
    "                with ZipFile(filename, 'r') as zipObj:\n",
    "                    # Extract all the contents of zip file in current directory\n",
    "                    zipObj.extractall(os.path.dirname(filename))\n",
    "\n",
    "                # clear up the zip file\n",
    "                os.remove(filename)\n",
    "            except:\n",
    "                print(\"Failed to unzip....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "    unzipped_file = HAPI_dict['filenames'][0].replace('.zip','.SEN3')\n",
    "else:\n",
    "    unzipped_file = glob.glob(os.path.join(download_dir_path,'*OL_2_WRR*.SEN3'))[0]\n",
    "\n",
    "input_root    = os.path.dirname(unzipped_file)\n",
    "input_path    = os.path.basename(unzipped_file)\n",
    "file_name_chl = 'chl_nn.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll quickly check, in the next box, if your data path is ok, and that the data file exists check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path length name seems fine\n",
      "Found the required data file\n"
     ]
    }
   ],
   "source": [
    "# quick path length check (some windows versions have a problem with long file paths)\n",
    "if len(os.path.join(input_root,input_path,file_name_chl)) > 259 \\\n",
    "  or len(os.path.join(input_root,input_path,file_name_chl)) > 248:\n",
    "    print('Beware, your path name is quite long. Consider moving your data to a new directory')\n",
    "else:\n",
    "    print('Path length name seems fine')\n",
    "    \n",
    "if os.path.exists(os.path.join(input_root,input_path,file_name_chl)):\n",
    "    print('Found the required data file')\n",
    "else:\n",
    "    print('Data file missing. Please check your path and file name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='otherdata'></a>4.0 Further options for getting data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='codarep_search'></a>4.1 Reprocessed data on CODA REP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='datacentre_search'></a>4.2 Older data from the EUMETSAT data centre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='sentinel-downloader'></a>4.3 Downloading data from CODA using the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='olci_eumetview'></a>4.4 OLCI maps and data from EUMETView WMS and WCS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"11_OLCI_overview.iynb\"><< OLCI Overview</a><span style=\"float:right;\"><a href=\"./13_OLCI_spatial_interrogation.ipynb\">1.2 - OLCI spatial interrogation >></a> \n",
    "    \n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/ocean\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int>Contact helpdesk for support </a> | <a href=mailto:Copernicus.training@eumetsat.int>Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
